import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import japanize_matplotlib
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import shap
import streamlit.components.v1 as components

st.title("ğŸš— è»Šã®ç‡ƒè²»äºˆæ¸¬ã‚¢ãƒ—ãƒªï¼ˆæ”¹å–„ç‰ˆï¼‰")

# ===== ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿ =====
model = joblib.load("src/model.pkl")
scaler = joblib.load("src/scaler.pkl")


# ===== å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  =====
cylinders = st.number_input("ã‚·ãƒªãƒ³ãƒ€ãƒ¼æ•°", min_value=3, max_value=12, value=4)
displacement = st.number_input("æ’æ°—é‡ (cu inches)", min_value=50, max_value=500, value=200)
horsepower = st.number_input("é¦¬åŠ› (hp)", min_value=40, max_value=250, value=100)
weight = st.number_input("é‡é‡ (lbs)", min_value=1500, max_value=5000, value=2500)
acceleration = st.number_input("åŠ é€Ÿåº¦ (0-60mph)", min_value=5.0, max_value=25.0, value=15.0)
model_year = st.slider("ãƒ¢ãƒ‡ãƒ«å¹´å¼", 70, 82, 76)

origin = st.selectbox(
    "è£½é€ å›½ (origin)",
    [1, 2, 3],
    index=0,
    format_func=lambda x: {1: "USA", 2: "Europe", 3: "Japan"}[x]
)


# ===== äºˆæ¸¬å‡¦ç† =====
if st.button("ç‡ƒè²»ã‚’äºˆæ¸¬"):

    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ•´å½¢
    X_new = pd.DataFrame([[cylinders, displacement, weight, acceleration, model_year, origin]],
                         columns=["cylinders", "displacement", "weight", "acceleration", "model year", "origin"])

    # One-hot encoding
    X_new = pd.get_dummies(X_new, columns=["origin"], drop_first=True)

    # åˆ—åè£œæ­£ï¼ˆ.0 â†’ ç„¡ã—ï¼‰
    X_new.columns = X_new.columns.str.replace(".0", "", regex=False)

    # å­¦ç¿’æ™‚ã¨åˆ—é †ãƒ»å½¢ã‚’æƒãˆã‚‹
    X_new = X_new.reindex(
        columns=["cylinders", "displacement", "weight", "acceleration", "model year", "origin_2", "origin_3"],
        fill_value=0
    )

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    X_new_scaled = scaler.transform(X_new)

    # äºˆæ¸¬
    mpg_pred = model.predict(X_new_scaled).item()
    st.success(f"äºˆæ¸¬ç‡ƒè²»: {mpg_pred:.2f} MPG")


    # ===== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½å¯è¦–åŒ– =====
    X_test = pd.read_csv("data/processed/X_test.csv")
    y_test = pd.read_csv("data/processed/y_test.csv")["mpg"]

    # OneHotåŒ–å‡¦ç†
    X_test = pd.get_dummies(X_test, columns=["origin"], drop_first=True)
    X_test.columns = X_test.columns.str.replace(".0", "", regex=False)
    X_test = X_test.reindex(columns=X_new.columns, fill_value=0)

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    X_test_scaled = scaler.transform(X_test)
    y_pred = model.predict(X_test_scaled)

    # æ•£å¸ƒå›³
    fig1, ax1 = plt.subplots(figsize=(5, 5))
    sns.scatterplot(x=y_test.values.flatten(), y=y_pred.flatten(), ax=ax1)
    ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--")
    ax1.set_xlabel("å®Ÿæ¸¬å€¤ MPG")
    ax1.set_ylabel("äºˆæ¸¬å€¤ MPG")
    ax1.set_title("å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤")
    st.pyplot(fig1)

    # èª¤å·®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    errors = y_test.values.flatten() - y_pred.flatten()
    fig2, ax2 = plt.subplots(figsize=(5, 4))
    sns.histplot(errors, bins=20, kde=True, ax=ax2)
    ax2.set_xlabel("èª¤å·® (å®Ÿæ¸¬ - äºˆæ¸¬)")
    ax2.set_title("äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒ")
    st.pyplot(fig2)

    # æ•°å€¤è©•ä¾¡
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    st.write(f"ğŸ“Š RMSE: {rmse:.3f}")
    st.write(f"ğŸ“ˆ RÂ²ã‚¹ã‚³ã‚¢: {r2:.3f}")


    # ===== SHAP Summary Plot =====
    st.subheader("ğŸ“Š SHAP Summary Plotï¼ˆç‰¹å¾´é‡ã®é‡è¦åº¦ï¼‰")

    explainer = shap.TreeExplainer(model)
    shap_values = explainer(X_test_scaled)

    fig_summary = plt.figure(figsize=(8, 5))
    shap.summary_plot(shap_values.values, X_test, show=False)
    st.pyplot(fig_summary)


    # ===== SHAP Force Plot =====
    st.subheader("ğŸ§  ãƒ¢ãƒ‡ãƒ«ã®åˆ¤æ–­ç†ç”±ï¼ˆSHAP Decision Plotï¼‰")
    try:
        st.image("outputs/decision_plot_example.png")
    except:
        st.warning("âš  SHAPç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚`python src/shap_analysis.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")